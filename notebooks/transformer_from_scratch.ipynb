{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5f67bb",
   "metadata": {},
   "source": [
    "### Transformer Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e25622",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eaaf76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System dependencies\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "\n",
    "# Torch dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data loaders\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a91279",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    ### Data config\n",
    "    \"num_classes\": 4,\n",
    "    \n",
    "    ### NLP config\n",
    "    \"max_vocab_size\": 20000,\n",
    "    \"pad_token\": \"<pad>\",\n",
    "    \"unk_token\": \"<unk>\",\n",
    "    \n",
    "    ### system settings\n",
    "    \"seed\": 42,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b41061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    torch.manual_seed(CONFIG[\"seed\"])\n",
    "    \n",
    "setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c516e31",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce625437",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "label_map = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c971714",
   "metadata": {},
   "source": [
    "#### Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenizer\n",
    "\n",
    "def tokenize(text):\n",
    "    # text.lower() - lowercase all the text samples\n",
    "    # text.split() - split the sentence into words\n",
    "    return text.lower().split() # [\"word1\", \"word2\", \"word3\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a03b1271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ca04239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wall',\n",
       " 'st.',\n",
       " 'bears',\n",
       " 'claw',\n",
       " 'back',\n",
       " 'into',\n",
       " 'the',\n",
       " 'black',\n",
       " '(reuters)',\n",
       " 'reuters',\n",
       " '-',\n",
       " 'short-sellers,',\n",
       " 'wall',\n",
       " \"street's\",\n",
       " 'dwindling\\\\band',\n",
       " 'of',\n",
       " 'ultra-cynics,',\n",
       " 'are',\n",
       " 'seeing',\n",
       " 'green',\n",
       " 'again.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(train_data[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88d0f6",
   "metadata": {},
   "source": [
    "#### Building Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e56ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter() # map each word to its number of appearances\n",
    "\n",
    "for item in train_data:\n",
    "    counter.update(tokenize(item[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a67af01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall : 1375\n",
      "st. : 1192\n",
      "bears : 344\n",
      "claw : 17\n",
      "back : 3868\n",
      "into : 6628\n",
      "the : 203234\n"
     ]
    }
   ],
   "source": [
    "# index, (value, key)\n",
    "for i, (word, num) in enumerate(counter.items()):\n",
    "    print(f\"{word} : {num}\")\n",
    "    \n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b477bd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158733"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c93ff2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG[\"max_vocab_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8866008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19998"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building the vocab based on MAX_VOCAB_SIZE\n",
    "most_common = counter.most_common(CONFIG[\"max_vocab_size\"] - 2) # 2 custom vocab - PAD and UNK\n",
    "\n",
    "len(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0a532f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<pad>', '<unk>')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG[\"pad_token\"], CONFIG[\"unk_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca8159dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    CONFIG[\"pad_token\"]: 0, # to pad all the sentences to the same length\n",
    "    CONFIG[\"unk_token\"]: 1  # for the unknown tokens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c11412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make up the vocabulary\n",
    "\n",
    "for i, (word, _) in enumerate(most_common, start=2):\n",
    "    vocab[word] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96babc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab) == CONFIG[\"max_vocab_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0baa65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
